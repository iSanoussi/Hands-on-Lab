{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2a26BI9fOZLn4pwEXvUEa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iSanoussi/Hands-on-Lab/blob/main/Web_Scraping_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1 - Hands-on Lab : Web Scraping**"
      ],
      "metadata": {
        "id": "h0IWfTMPFXi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objectives** : In this lab you will perform the following:\n",
        "\n",
        "Extract information from a given web site\n",
        "Write the scraped data into a csv file."
      ],
      "metadata": {
        "id": "n_BWzur2FEO1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c03pa_76_gUk"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Website and pull in data\n",
        "\n",
        "URL = 'https://www.amazon.com/dp/B07FWCH9MQ/ref=sspa_dk_detail_6?psc=1&pd_rd_i=B07FWCH9MQ&pd_rd_w=ixKXg&content-id=amzn1.sym.eb7c1ac5-7c51-4df5-ba34-ca810f1f119a&pf_rd_p=eb7c1ac5-7c51-4df5-ba34-ca810f1f119a&pf_rd_r=50026MZXW8KJEVRRC7A0&pd_rd_wg=fiUG2&pd_rd_r=08e68089-9b34-4b05-a9c1-9008aedc679c&s=apparel&sp_csd=d2lkZ2V0TmFtZT1zcF9kZXRhaWw'\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "page = requests.get(URL, headers=headers)\n",
        "\n",
        "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
        "\n",
        "title = soup2.find(id='productTitle').get_text()\n",
        "\n",
        "price = soup2.find(id='corePriceDisplay_desktop_feature_div').get_text()\n",
        "\n",
        "\n",
        "print(title)\n",
        "print(price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0CaM5Ho_ihF",
        "outputId": "f992e9c7-9d80-424e-fe4b-32f96baf06e2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                    Womens I Like Coffee and Maybe 3 People T Shirt Funny Sarcastic Tee for Ladies\n",
            "                   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                    $12.99\n",
            "                   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                      $\n",
            "                     \n",
            "\n",
            "                      12\n",
            "                      \n",
            "                       .\n",
            "                      \n",
            "\n",
            "\n",
            "                      99\n",
            "                     \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up the data a little bit\n",
        "\n",
        "price = price.strip()[1:7]\n",
        "title = title.strip()\n",
        "\n",
        "print(title)\n",
        "print(price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09-fDvxi_xjQ",
        "outputId": "6ebd4f3d-b9a5-4acd-9173-887b42ec2d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Womens I Like Coffee and Maybe 3 People T Shirt Funny Sarcastic Tee for Ladies\n",
            "12.99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Timestamp for the output to track the time that data was collected\n",
        "\n",
        "import datetime\n",
        "\n",
        "today = datetime.date.today()\n",
        "\n",
        "print(today)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL-sE19K_zzf",
        "outputId": "46807e85-fbe2-4735-dc48-c1bed157693b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV and write headers and data into the file\n",
        "\n",
        "import csv\n",
        "\n",
        "header = ['Title', 'Price', 'Date']\n",
        "data = [title, price, today]\n",
        "\n",
        "\n",
        "with open('WebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "pI1Uxyvs_zw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"WebScraperDataset.csv\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmkbjn_m_zuv",
        "outputId": "9b2cb6af-bac2-427a-ccca-472ac4ae71fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  Price        Date\n",
            "0  Womens I Like Coffee and Maybe 3 People T Shir...  12.99  2024-06-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we are appending data to the csv\n",
        "\n",
        "with open('WebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "b_BnxE5Z_zsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I want to check the price every day so I will define a function to do all the previous steps and then by the time as second the function would work everyday:"
      ],
      "metadata": {
        "id": "8ALaP38VAw8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine all of the above code into one function for the purpose of automation:\n",
        "\n",
        "\n",
        "def check_price():\n",
        "    URL = 'https://www.amazon.com/dp/B07FWCH9MQ/ref=sspa_dk_detail_6?psc=1&pd_rd_i=B07FWCH9MQ&pd_rd_w=ixKXg&content-id=amzn1.sym.eb7c1ac5-7c51-4df5-ba34-ca810f1f119a&pf_rd_p=eb7c1ac5-7c51-4df5-ba34-ca810f1f119a&pf_rd_r=50026MZXW8KJEVRRC7A0&pd_rd_wg=fiUG2&pd_rd_r=08e68089-9b34-4b05-a9c1-9008aedc679c&s=apparel&sp_csd=d2lkZ2V0TmFtZT1zcF9kZXRhaWw'\n",
        "\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "    page = requests.get(URL, headers=headers)\n",
        "\n",
        "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
        "\n",
        "    title = soup2.find(id='productTitle').get_text()\n",
        "\n",
        "    price = soup2.find(id='corePriceDisplay_desktop_feature_div').get_text()\n",
        "\n",
        "    price = price.strip()[1:7]\n",
        "    title = title.strip()\n",
        "\n",
        "    import datetime\n",
        "\n",
        "    today = datetime.date.today()\n",
        "\n",
        "    import csv\n",
        "\n",
        "    header = ['Title', 'Price', 'Date']\n",
        "    data = [title, price, today]\n",
        "\n",
        "    with open('WebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(data)\n"
      ],
      "metadata": {
        "id": "k9Xk9zHO_zp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWkGXLq-A8j2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}